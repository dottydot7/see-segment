{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bf00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path hack so that we can import see library.\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95dac5",
   "metadata": {},
   "source": [
    "## Defining you own parameter space\n",
    "This notebook demonstrates how one may define their own Classifier Search Space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eea79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from see.classifiers import Classifier, ClassifierParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72a704",
   "metadata": {},
   "source": [
    "We will use the `Classifier#set_search_space` class method to set our custom search space to be the Classifier Search Space that we can run Genetic Search over. We first define a simple custom space dictionaries that will be passed into `Classifier#set_search_space`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715b0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, initialize custom search space dictionaries.\n",
    "\n",
    "# These two dictionaries represent\n",
    "# the algorithm space and the\n",
    "# parameter space respectively.\n",
    "# The keys of these dictionaries\n",
    "# are the algorithm names and\n",
    "# the parameter names respectively.\n",
    "new_algo_space = dict()\n",
    "new_param_space = dict()\n",
    "\n",
    "# The values of the new_algo_space\n",
    "# dictionary needs to be ClassifierContainer\n",
    "# Classes (not instances!). Many have already\n",
    "# been pre-defined\n",
    "# in the classifiers.py file.\n",
    "\n",
    "# The values of the parameter space dictionary (i.e. new_param_space)\n",
    "# needs to be a tuple: (range, description).\n",
    "# `range` is a list of possible values for the\n",
    "# the corresponding parameter name.\n",
    "# `description` is used to document and\n",
    "# describe the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d677e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a Classifier algorithm to the \n",
    "# search space, one first needs to pick or define\n",
    "# the corresponding classifier container.\n",
    "# Existing Classifier Containers have\n",
    "# been defined in classifiers.py.\n",
    "\n",
    "# First add import and add the container \n",
    "# to the algorithm space dictionary.\n",
    "from see.classifiers import MLPContainer\n",
    "\n",
    "new_algo_space[\"MLP Neural Network\"] = MLPContainer\n",
    "\n",
    "# Then, add its parameters to the parameter space dictionary\n",
    "for param in MLPContainer().paramindexes:\n",
    "    new_param_space[param] = ClassifierParams.get_param(param)\n",
    "    \n",
    "# Right now in order to add a new classifier to the search space\n",
    "# one would have to define a ClassifierContainer class\n",
    "# and add its respective parameters and parameter ranges carefully.\n",
    "# There is not a simpler method \n",
    "# to directly add Classifier and custom search space yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad544c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, one may manually define a search space within\n",
    "# the Classifier class itself. Look at the Classifier#use_dhahri_space\n",
    "# and Classifier#use_tutorial_space class methods as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7701db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set the custom search space as the Classifier space, run:\n",
    "Classifier.set_search_space(new_algo_space, new_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9128db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLP Neural Network': <class 'see.classifiers.MLPContainer'>}\n",
      "Possible Parameters\n",
      "['algorithm', 'activation', 'alpha', 'max_iter', 'solver']\n",
      "\n",
      "\n",
      "Parameter Ranges\n",
      "{   'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
      "    'algorithm': ['MLP Neural Network'],\n",
      "    'alpha': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
      "    'max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
      "    'solver': ['lbfgs', 'sgd', 'adam']}\n",
      "\n",
      "\n",
      "Parameter Descriptions\n",
      "{   'activation': 'Activation function for the hidden layer of neural network.',\n",
      "    'algorithm': 'string code for the algorithm',\n",
      "    'alpha': 'L2 penalty regularization parameter',\n",
      "    'max_iter': 'Number of iterations for the algorithm',\n",
      "    'solver': 'The solver for weight optimization of neural network.'}\n"
     ]
    }
   ],
   "source": [
    "# Check the search space by running:\n",
    "# Initialize Algorithm Space and Workflow\n",
    "import pprint\n",
    "\n",
    "algorithm_space = Classifier.algorithmspace\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(algorithm_space)\n",
    "\n",
    "# Print possible parameters\n",
    "print('Possible Parameters')\n",
    "pp.pprint(ClassifierParams.pkeys)\n",
    "print('\\n')\n",
    "# Print parameter ranges\n",
    "print('Parameter Ranges')\n",
    "pp.pprint(ClassifierParams.ranges)\n",
    "print('\\n')\n",
    "print('Parameter Descriptions')\n",
    "# Print descriptions of parameters\n",
    "pp.pprint(ClassifierParams.descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9aa70",
   "metadata": {},
   "source": [
    "Let's test our custom workspace using Genetic Search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d166d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = identity\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 100\n",
      "\tsolver = lbfgs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from see.Workflow import workflow\n",
    "from see.classifier_fitness import ClassifierFitness\n",
    "\n",
    "# Initialize workflow for Genetic Search\n",
    "workflow.addalgos([Classifier, ClassifierFitness])\n",
    "wf = workflow()\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ee2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a new random population\n",
      "Generation 0/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = identity\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 800\n",
      "\tsolver = adam\n",
      "\n",
      "Time: 0.074 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 1e-05\n",
      "\tmax_iter = 800\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.628 s\n",
      "fitness=0.125\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 1000\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.048 s\n",
      "fitness=0.125\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.0001\n",
      "\tmax_iter = 100\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.063 s\n",
      "fitness=0.19999999999999996\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = lbfgs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.532 s\n",
      "fitness=0.125\n",
      "\n",
      "#BEST [0.125,  ['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']]\n",
      "# GEN HOF_index fitness ind|0;0;0.125;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|0;1;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|0;2;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|0;3;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|0;4;0.6;['MLP Neural Network', 'identity', 1e-06, 800, 'adam']\n",
      "# GEN population_index fitness ind|0;0;0.6;['MLP Neural Network', 'identity', 1e-06, 800, 'adam']\n",
      "# GEN population_index fitness ind|0;1;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN population_index fitness ind|0;2;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN population_index fitness ind|0;3;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN population_index fitness ind|0;4;0.125;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "Generation 1/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 1e-05\n",
      "\tmax_iter = 400\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.333 s\n",
      "fitness=0.25\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.541 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = lbfgs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.484 s\n",
      "fitness=0.22499999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 1000\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.714 s\n",
      "fitness=0.17500000000000004\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 500\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.048 s\n",
      "fitness=0.125\n",
      "\n",
      "#BEST [0.09999999999999998,  ['MLP Neural Network', 'tanh', 0.001, 600, 'adam']]\n",
      "# GEN HOF_index fitness ind|1;0;0.09999999999999998;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|1;1;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|1;2;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|1;3;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|1;4;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|1;5;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|1;6;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|1;7;0.25;['MLP Neural Network', 'tanh', 1e-05, 400, 'adam']\n",
      "# GEN HOF_index fitness ind|1;8;0.6;['MLP Neural Network', 'identity', 1e-06, 800, 'adam']\n",
      "# GEN population_index fitness ind|1;0;0.25;['MLP Neural Network', 'tanh', 1e-05, 400, 'adam']\n",
      "# GEN population_index fitness ind|1;1;0.09999999999999998;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN population_index fitness ind|1;2;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN population_index fitness ind|1;3;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN population_index fitness ind|1;4;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "Generation 2/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = identity\n",
      "\talpha = 0.0001\n",
      "\tmax_iter = 1000\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.013 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.0001\n",
      "\tmax_iter = 100\n",
      "\tsolver = adam\n",
      "\n",
      "Time: 0.105 s\n",
      "fitness=0.375\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.837 s\n",
      "fitness=0.125\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.555 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 600\n",
      "\tsolver = lbfgs\n",
      "\n",
      "Time: 0.05 s\n",
      "fitness=0.25\n",
      "\n",
      "#BEST [0.09999999999999998,  ['MLP Neural Network', 'relu', 0.001, 500, 'adam']]\n",
      "# GEN HOF_index fitness ind|2;0;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|2;1;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|2;2;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;3;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;4;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;5;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|2;6;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;7;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;8;0.25;['MLP Neural Network', 'tanh', 1e-06, 600, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|2;9;0.25;['MLP Neural Network', 'tanh', 1e-05, 400, 'adam']\n",
      "# GEN population_index fitness ind|2;0;0.6;['MLP Neural Network', 'identity', 0.0001, 1000, 'lbfgs']\n",
      "# GEN population_index fitness ind|2;1;0.375;['MLP Neural Network', 'relu', 0.0001, 100, 'adam']\n",
      "# GEN population_index fitness ind|2;2;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN population_index fitness ind|2;3;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN population_index fitness ind|2;4;0.25;['MLP Neural Network', 'tanh', 1e-06, 600, 'lbfgs']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "Generation 3/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = identity\n",
      "\talpha = 0.01\n",
      "\tmax_iter = 900\n",
      "\tsolver = sgd\n",
      "\n",
      "Time: 0.056 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = logistic\n",
      "\talpha = 1e-05\n",
      "\tmax_iter = 300\n",
      "\tsolver = adam\n",
      "\n",
      "Time: 0.031 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.511 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.503 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.753 s\n",
      "fitness=0.125\n",
      "\n",
      "#BEST [0.09999999999999998,  ['MLP Neural Network', 'relu', 0.001, 500, 'adam']]\n",
      "# GEN HOF_index fitness ind|3;0;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|3;1;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|3;2;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;3;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;4;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;5;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|3;6;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;7;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;8;0.25;['MLP Neural Network', 'tanh', 1e-06, 600, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|3;9;0.25;['MLP Neural Network', 'tanh', 1e-05, 400, 'adam']\n",
      "# GEN population_index fitness ind|3;0;0.6;['MLP Neural Network', 'identity', 0.01, 900, 'sgd']\n",
      "# GEN population_index fitness ind|3;1;0.6;['MLP Neural Network', 'logistic', 1e-05, 300, 'adam']\n",
      "# GEN population_index fitness ind|3;2;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN population_index fitness ind|3;3;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN population_index fitness ind|3;4;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "Generation 4/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 800\n",
      "\tsolver = sgd\n",
      "\n",
      "Time: 0.021 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.01\n",
      "\tmax_iter = 200\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.217 s\n",
      "fitness=0.525\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.48 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = tanh\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.564 s\n",
      "fitness=0.125\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.555 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "#BEST [0.09999999999999998,  ['MLP Neural Network', 'relu', 0.001, 600, 'adam']]\n",
      "# GEN HOF_index fitness ind|4;0;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|4;1;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|4;2;0.125;['MLP Neural Network', 'tanh', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|4;3;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|4;4;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|4;5;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|4;6;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|4;7;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|4;8;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|4;9;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN population_index fitness ind|4;0;0.6;['MLP Neural Network', 'tanh', 1e-06, 800, 'sgd']\n",
      "# GEN population_index fitness ind|4;1;0.525;['MLP Neural Network', 'tanh', 0.01, 200, 'adam']\n",
      "# GEN population_index fitness ind|4;2;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN population_index fitness ind|4;3;0.125;['MLP Neural Network', 'tanh', 0.001, 500, 'adam']\n",
      "# GEN population_index fitness ind|4;4;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 600, 'adam']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "Generation 5/5 of population size 5\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = identity\n",
      "\talpha = 1e-06\n",
      "\tmax_iter = 100\n",
      "\tsolver = adam\n",
      "\n",
      "Time: 0.017 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = logistic\n",
      "\talpha = 1e-05\n",
      "\tmax_iter = 600\n",
      "\tsolver = sgd\n",
      "\n",
      "Time: 0.038 s\n",
      "fitness=0.6\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.537 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 600\n",
      "\tsolver = adam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.536 s\n",
      "fitness=0.125\n",
      "\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\talgorithm = MLP Neural Network\n",
      "\tactivation = relu\n",
      "\talpha = 0.001\n",
      "\tmax_iter = 500\n",
      "\tsolver = adam\n",
      "\n",
      "Time: 0.479 s\n",
      "fitness=0.09999999999999998\n",
      "\n",
      "#BEST [0.09999999999999998,  ['MLP Neural Network', 'relu', 0.001, 600, 'adam']]\n",
      "# GEN HOF_index fitness ind|5;0;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|5;1;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|5;2;0.125;['MLP Neural Network', 'tanh', 0.001, 500, 'adam']\n",
      "# GEN HOF_index fitness ind|5;3;0.125;['MLP Neural Network', 'tanh', 0.001, 600, 'adam']\n",
      "# GEN HOF_index fitness ind|5;4;0.125;['MLP Neural Network', 'relu', 1e-06, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|5;5;0.22499999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|5;6;0.125;['MLP Neural Network', 'relu', 1e-06, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|5;7;0.125;['MLP Neural Network', 'relu', 1e-05, 800, 'adam']\n",
      "# GEN HOF_index fitness ind|5;8;0.17500000000000004;['MLP Neural Network', 'relu', 0.001, 1000, 'lbfgs']\n",
      "# GEN HOF_index fitness ind|5;9;0.19999999999999996;['MLP Neural Network', 'tanh', 0.0001, 100, 'lbfgs']\n",
      "# GEN population_index fitness ind|5;0;0.6;['MLP Neural Network', 'identity', 1e-06, 100, 'adam']\n",
      "# GEN population_index fitness ind|5;1;0.6;['MLP Neural Network', 'logistic', 1e-05, 600, 'sgd']\n",
      "# GEN population_index fitness ind|5;2;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 600, 'adam']\n",
      "# GEN population_index fitness ind|5;3;0.125;['MLP Neural Network', 'relu', 0.001, 600, 'adam']\n",
      "# GEN population_index fitness ind|5;4;0.09999999999999998;['MLP Neural Network', 'relu', 0.001, 500, 'adam']\n",
      "Mutating Population\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "using workflow mutate algorithm and looping over workflow\n",
      "CPU times: user 10.2 s, sys: 39.9 ms, total: 10.2 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davin/Documents/GitHub/see-segment/see-clasify/envs/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['MLP Neural Network', 'relu', 0.0001, 200, 'sgd'],\n",
       " ['MLP Neural Network', 'relu', 1e-05, 1000, 'lbfgs'],\n",
       " ['MLP Neural Network', 'relu', 0.001, 600, 'adam'],\n",
       " ['MLP Neural Network', 'relu', 0.001, 600, 'adam'],\n",
       " ['MLP Neural Network', 'relu', 0.001, 500, 'adam']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from see import GeneticSearch\n",
    "num_generations = 5\n",
    "\n",
    "from see.base_classes import pipedata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_circles\n",
    "from see.classifier_helpers import helpers\n",
    "\n",
    "# Create Simple Dataset\n",
    "circles_ds = pipedata()\n",
    "circles_ds.name = 'Circles Dataset'\n",
    "circles_ds.X, circles_ds.y = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Preprocess data\n",
    "circles_ds.X = StandardScaler().fit_transform(circles_ds.X)\n",
    "\n",
    "# Create pipeline data that can be passed into the classifier pipeline\n",
    "pipeline_data = helpers.generate_train_test_set(circles_ds.X, circles_ds.y)\n",
    "\n",
    "my_evolver = GeneticSearch.Evolver(workflow, pipeline_data, pop_size=5)\n",
    "my_evolver.run(ngen=num_generations, print_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc30c2",
   "metadata": {},
   "source": [
    "## Modifying the search space\n",
    "This section demonstrates how one may modify the own Classifier Search Space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f231b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from see.classifiers import Classifier, ClassifierParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc979dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MLP Neural Network'], 'string code for the algorithm')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the range and description of one parameter (such as 'algorithm')\n",
    "ClassifierParams.get_param('algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a2b37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm:  MLP Neural Network\n",
      "-------------------------------\n",
      "activation\n",
      "description:  Activation function for the hidden layer of neural network.\n",
      "range:  ['identity', 'logistic', 'tanh', 'relu']\n",
      "\n",
      "\n",
      "alpha\n",
      "description:  L2 penalty regularization parameter\n",
      "range:  [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
      "\n",
      "\n",
      "max_iter\n",
      "description:  Number of iterations for the algorithm\n",
      "range:  [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
      "\n",
      "\n",
      "solver\n",
      "description:  The solver for weight optimization of neural network.\n",
      "range:  ['lbfgs', 'sgd', 'adam']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the parameters of each algorithm\n",
    "for clf in Classifier.algorithmspace:\n",
    "    params = (Classifier.algorithmspace[clf]().paramindexes)\n",
    "    # To see the ranges\n",
    "    print('Algorithm: ', clf)\n",
    "    print('-------------------------------')\n",
    "    for param_name in params:\n",
    "        print(param_name)\n",
    "        ranges, description = ClassifierParams.get_param(param_name)\n",
    "        print('description: ', description)\n",
    "        print('range: ', ranges)\n",
    "        print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb94df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the range\n",
    "ClassifierParams.set_param_ranges('activation', ['o'])\n",
    "# To change the description\n",
    "ClassifierParams.set_param_description('activation', 'bad description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61212bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranges:  ['o']\n",
      "description:  bad description\n"
     ]
    }
   ],
   "source": [
    "# Check the new range and description\n",
    "ranges, description = ClassifierParams.get_param('activation')\n",
    "print('ranges: ', ranges)\n",
    "print('description: ', description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70c4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a parameter\n",
    "ClassifierParams.add('l', [0, 1], 'random letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16e339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name:  algorithm\n",
      "description:  string code for the algorithm\n",
      "ranges:  ['MLP Neural Network']\n",
      "\n",
      "\n",
      "Parameter name:  activation\n",
      "description:  bad description\n",
      "ranges:  ['o']\n",
      "\n",
      "\n",
      "Parameter name:  alpha\n",
      "description:  L2 penalty regularization parameter\n",
      "ranges:  [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
      "\n",
      "\n",
      "Parameter name:  max_iter\n",
      "description:  Number of iterations for the algorithm\n",
      "ranges:  [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
      "\n",
      "\n",
      "Parameter name:  solver\n",
      "description:  The solver for weight optimization of neural network.\n",
      "ranges:  ['lbfgs', 'sgd', 'adam']\n",
      "\n",
      "\n",
      "Parameter name:  l\n",
      "description:  random letter\n",
      "ranges:  [0, 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see check the parameter space again for the new parameter\n",
    "for param_name in ClassifierParams.pkeys:\n",
    "    print('Parameter name: ', param_name)\n",
    "    ranges, description = ClassifierParams.get_param(param_name)\n",
    "    print('description: ', description)\n",
    "    print('ranges: ', ranges)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
